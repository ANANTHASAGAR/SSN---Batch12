{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Write a Python NLTK program to remove stop words form the given text below\n",
    "\n",
    "From Wikipedia:\n",
    "In computing, stop words are words which are filtered out before or after processing of natural language data (text). Though \"stop words\" usually refers to the most common words in a language, there is no single universal list of stop words used by all natural language processing tools, and indeed not all tools even use such a list. Some tools specifically avoid removing these stop words to support phrase search.\n",
    "\n",
    "Any group of words can be chosen as the stop words for a given purpose. For some search engines, these are some of the most common, short function words, such as the, is, at, which, and on. In this case, stop words can cause problems when searching for phrases that include them, particularly in names such as \"The Who\", \"The The\", or \"Take That\". Other search engines remove some of the most common words-including lexical words, such as \"want\"-from a query in order to improve performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Example:\n",
      "\n",
      "Original string:\n",
      "\n",
      "In computing, stop words are words which are filtered out before or after \n",
      "processing of natural language data (text). Though \"stop words\" usually \n",
      "refers to the most common words in a language, there is no single universal \n",
      "list of stop words used by all natural language processing tools, and \n",
      "indeed not all tools even use such a list. Some tools specifically avoid \n",
      "removing these stop words to support phrase search.\n",
      "\n",
      "\n",
      "After removing stop words from the said text:\n",
      "['In', 'computing,', 'stop', 'words', 'words', 'filtered', 'processing', 'natural', 'language', 'data', '(text).', 'Though', '\"stop', 'words\"', 'usually', 'refers', 'common', 'words', 'language,', 'single', 'universal', 'list', 'stop', 'words', 'used', 'natural', 'language', 'processing', 'tools,', 'indeed', 'tools', 'even', 'use', 'list.', 'Some', 'tools', 'specifically', 'avoid', 'removing', 'stop', 'words', 'support', 'phrase', 'search.']\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Write a Python NLTK program to omit some given stop words from the stopwords list.\n",
    "\n",
    "Omit - 'again', 'once' and 'from': List of fresh stopwords in English:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of stopwords in English:\n",
      "{'shouldn', 'just', 'nor', 'whom', 'off', \"should've\", 'if', 'once', 'about', 'haven', 'mustn', 'ain', 'was', 'a', 'as', \"mightn't\", \"you've\", 'why', 'herself', 'yours', 'should', 'which', 'she', 'weren', 'how', 'what', \"shan't\", 'himself', 'wasn', 'its', \"you're\", 'that', 'their', 'the', 'and', 'won', 'any', 'do', 'by', 'when', 'than', \"aren't\", 'some', 'itself', 'other', 'over', 'will', 'doesn', 'me', 'hadn', 'too', 'wouldn', 'up', 'ourselves', 'your', 'll', 'is', \"she's\", \"hasn't\", 'into', 'or', 'her', \"needn't\", 'here', 't', 'had', 'this', \"won't\", 'out', 'until', 'an', 'but', \"haven't\", 'it', 'because', 'myself', 'such', 'no', 'o', 'down', 'hers', 'hasn', 'my', 'aren', 'same', 'didn', 're', 'mightn', \"wasn't\", 'his', 'y', 'not', \"it's\", 'ours', 'theirs', 'through', 'ma', 'them', 'shan', 'of', 'both', 'few', 'more', 'doing', 'from', \"weren't\", 'so', 'now', 'yourself', 'being', 'for', 'above', 'each', 'who', 'between', 'does', 'below', 'can', 'most', \"you'll\", 've', \"isn't\", 'our', \"wouldn't\", 'before', 'you', 'these', 'during', 'in', 'has', 'are', 'those', 'don', \"didn't\", 'be', 'again', 'under', 'only', \"shouldn't\", 'i', 'against', 'having', 'to', 'on', \"mustn't\", \"that'll\", \"doesn't\", 's', 'at', 'then', 'm', 'where', 'been', 'isn', 'him', \"you'd\", 'own', 'while', 'they', 'couldn', 'd', 'am', 'with', 'did', 'there', 'we', 'were', 'further', \"couldn't\", 'have', \"hadn't\", 'yourselves', 'all', 'after', \"don't\", 'needn', 'he', 'very', 'themselves'}\n",
      "\n",
      "Omit - 'again', 'once' and 'from':\n",
      "\n",
      "List of fresh stopwords in English:\n",
      "{'shouldn', 'just', 'nor', 'whom', 'off', \"should've\", 'if', 'about', 'haven', 'mustn', 'ain', 'was', 'a', 'as', \"mightn't\", \"you've\", 'why', 'herself', 'yours', 'should', 'which', 'she', 'weren', 'how', 'what', \"shan't\", 'himself', 'wasn', 'its', \"you're\", 'that', 'their', 'the', 'and', 'won', 'any', 'do', 'by', 'when', 'than', \"aren't\", 'some', 'itself', 'other', 'over', 'will', 'doesn', 'me', 'hadn', 'too', 'wouldn', 'up', 'ourselves', 'your', 'll', 'is', \"she's\", \"hasn't\", 'into', 'or', 'her', \"needn't\", 'here', 't', 'had', 'this', \"won't\", 'out', 'until', 'an', 'but', \"haven't\", 'it', 'because', 'myself', 'such', 'no', 'o', 'down', 'hers', 'hasn', 'my', 'aren', 'same', 'didn', 're', 'mightn', \"wasn't\", 'his', 'y', 'not', \"it's\", 'ours', 'theirs', 'through', 'ma', 'them', 'shan', 'of', 'both', 'few', 'more', 'doing', \"weren't\", 'so', 'now', 'yourself', 'being', 'for', 'above', 'each', 'who', 'between', 'does', 'below', 'can', 'most', \"you'll\", 've', \"isn't\", 'our', \"wouldn't\", 'before', 'you', 'these', 'during', 'in', 'has', 'are', 'those', 'don', \"didn't\", 'be', 'under', 'only', \"shouldn't\", 'i', 'against', 'having', 'to', 'on', \"mustn't\", \"that'll\", \"doesn't\", 's', 'at', 'then', 'm', 'where', 'been', 'isn', 'him', \"you'd\", 'own', 'while', 'they', 'couldn', 'd', 'am', 'with', 'did', 'there', 'we', 'were', 'further', \"couldn't\", 'have', \"hadn't\", 'yourselves', 'all', 'after', \"don't\", 'needn', 'he', 'very', 'themselves'}\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Write a Python NLTK program to find the definition and examples of a given word using WordNet.\n",
    "\n",
    "From Wikipedia,\n",
    "WordNet is a lexical database for the English language. It groups English words into sets of synonyms called synsets, provides short definitions and usage examples, and records a number of relations among these synonym sets or their members. WordNet can thus be seen as a combination of dictionary and thesaurus. While it is accessible to human users via a web browser, its primary use is in automatic text analysis and artificial intelligence applications. The database and software tools have been released under a BSD style license and are freely available for download from the WordNet website. Both the lexicographic data (lexicographer files) and the compiler (called grind) for producing the distributed database are available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defination of the said word:\n",
      "a hostile meeting of opposing military forces in the course of a war\n",
      "\n",
      "Examples of the word in use::\n",
      "['Grant won a decisive victory in the battle of Chickamauga', 'he lost his romantic ideas about war when he got into a real engagement']\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Write a Python NLTK program to create a list of words from a given string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original string:\n",
      "Joe waited for the train. The train was late. Mary and Samantha took the bus. I looked for Mary and Samantha at the bus station.\n",
      "\n",
      "List of words:\n",
      "['Joe', 'waited', 'for', 'the', 'train', '.', 'The', 'train', 'was', 'late', '.', 'Mary', 'and', 'Samantha', 'took', 'the', 'bus', '.', 'I', 'looked', 'for', 'Mary', 'and', 'Samantha', 'at', 'the', 'bus', 'station', '.']\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Write a Python NLTK program to split the text to sentence and then into a list of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original string:\n",
      "\n",
      "Joe waited for the train. The train was late. \n",
      "Mary and Samantha took the bus. \n",
      "I looked for Mary and Samantha at the bus station.\n",
      "\n",
      "\n",
      "Sentence-tokenized copy in a list:\n",
      "['\\nJoe waited for the train.', 'The train was late.', 'Mary and Samantha took the bus.', 'I looked for Mary and Samantha at the bus station.']\n",
      "\n",
      "List of Words:\n",
      "[['Joe', 'waited', 'for', 'the', 'train.'], ['The', 'train', 'was', 'late.'], ['Mary', 'and', 'Samantha', 'took', 'the', 'bus.'], ['I', 'looked', 'for', 'Mary', 'and', 'Samantha', 'at', 'the', 'bus', 'station.']]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Write a Python program to tokenize even the punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original string:\n",
      "Reset your password if you just can't remember your old one.\n",
      "\n",
      "Split all punctuation into separate tokens:\n",
      "['Reset', 'your', 'password', 'if', 'you', 'just', 'can', \"'\", 't', 'remember', 'your', 'old', 'one', '.']\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Write a Python NLTK program to tokenize words, sentence wise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original string:\n",
      "Joe waited for the train. The train was late. Mary and Samantha took the bus. I looked for Mary and Samantha at the bus station.\n",
      "\n",
      "Tokenize words sentence wise:\n",
      "\n",
      "Read the list:\n",
      "['Joe', 'waited', 'for', 'the', 'train', '.']\n",
      "['The', 'train', 'was', 'late', '.']\n",
      "['Mary', 'and', 'Samantha', 'took', 'the', 'bus', '.']\n",
      "['I', 'looked', 'for', 'Mary', 'and', 'Samantha', 'at', 'the', 'bus', 'station', '.']\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Write a Python NLTK program that will read a given text through each line and look for sentences. Print each sentence and divide two sentences with “==============”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original Tweet:\n",
      "\n",
      "Mr. Smith waited for the train. The train was late.\n",
      "Mary and Samantha took the bus. I looked for Mary and\n",
      "Samantha at the bus station.\n",
      "\n",
      "Mr. Smith waited for the train.\n",
      "==============\n",
      "The train was late.\n",
      "==============\n",
      "Mary and Samantha took the bus.\n",
      "==============\n",
      "I looked for Mary and\n",
      "Samantha at the bus station.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Write a Python NLTK program to find the sets of synonyms and antonyms of a given word.\n",
    "\n",
    "From Winkled,\n",
    "WordNet is a lexical database for the English language. It groups English words into sets of synonyms called synsets, provides short definitions and usage examples, and records a number of relations among these synonym sets or their members."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Set of synonyms of the said word:\n",
      "{'death', 'ending', 'cease', 'terminal', 'end', 'closing', 'oddment', 'remainder', 'final_stage', 'goal', 'destruction', 'conclusion', 'remnant', 'stop', 'terminate', 'finish', 'last', 'close'}\n",
      "\n",
      "Set of antonyms of the said word:\n",
      "{'begin', 'beginning'}\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
